{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f4c06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train/MINDsmall_train] behaviors written -> /home/scur1695/ir2-colbert-news/baseline/data_downsampled_20k/original/train/MINDsmall_train/behaviors.tsv (rows: 62,668, unique users: 20,000)\n",
      "[train/MINDsmall_train] referenced news ids: 38,411\n",
      "[train/MINDsmall_train] filtering news.tsv -> /home/scur1695/ir2-colbert-news/baseline/data_downsampled_20k/original/train/MINDsmall_train/news.tsv\n",
      "[news] 38,411 rows kept out of ~51,282 lines (train/news.tsv)\n",
      "[train/MINDsmall_train] Done.\n",
      "\n",
      "[val] Copying validation split unchanged...\n",
      "[val] Done (unchanged).\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# --- One cell: Downsample MIND-small (train users) and keep referenced news safely ---\n",
    "\n",
    "import os, re, shutil, random\n",
    "from typing import Set\n",
    "import pandas as pd\n",
    "\n",
    "# ==== Edit these paths/params ====\n",
    "in_root  = \"/baseline/data/original\"\n",
    "out_root = \"/baseline/data_downsampled_20k/original\"\n",
    "seed = 42\n",
    "train_users = 20000\n",
    "val_users = -1   # set >0 if you also want to downsample val\n",
    "\n",
    "# ==========================\n",
    "# Helpers (no header games)\n",
    "# ==========================\n",
    "BEH_COLS = [\"impression_id\", \"user_id\", \"time\", \"click_history\", \"impressions\"]\n",
    "SEP = re.compile(r\"[,\\s|]+\")\n",
    "\n",
    "def read_behaviors(path: str) -> pd.DataFrame:\n",
    "    # behaviors.tsv in MIND has NO header and 5 columns\n",
    "    return pd.read_csv(path, sep=\"\\t\", header=None, names=BEH_COLS, dtype=str, quoting=3)\n",
    "\n",
    "def extract_news_from_behaviors(df: pd.DataFrame) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Collect news IDs from click_history and impressions.\n",
    "    Handles space/comma/pipe separators and trims '-0/-1' labels.\n",
    "    Keeps only IDs that look like MIND news IDs (start with 'N').\n",
    "    \"\"\"\n",
    "    news_ids: Set[str] = set()\n",
    "\n",
    "    # history\n",
    "    for h in df[\"click_history\"].fillna(\"\").astype(str):\n",
    "        if not h or h == \"-\":\n",
    "            continue\n",
    "        for tok in SEP.split(h.strip()):\n",
    "            tok = tok.strip()\n",
    "            if not tok:\n",
    "                continue\n",
    "            if \"-\" in tok:\n",
    "                tok = tok.split(\"-\", 1)[0]\n",
    "            news_ids.add(tok)\n",
    "\n",
    "    # impressions\n",
    "    for imp in df[\"impressions\"].fillna(\"\").astype(str):\n",
    "        if not imp:\n",
    "            continue\n",
    "        for tok in SEP.split(imp.strip()):\n",
    "            tok = tok.strip()\n",
    "            if not tok:\n",
    "                continue\n",
    "            if \"-\" in tok:\n",
    "                tok = tok.split(\"-\", 1)[0]\n",
    "            news_ids.add(tok)\n",
    "\n",
    "    return {nid for nid in news_ids if nid and nid[0] == \"N\"}\n",
    "\n",
    "def sample_users(df: pd.DataFrame, target_users: int, seed: int) -> Set[str]:\n",
    "    users = sorted(df[\"user_id\"].astype(str).unique().tolist())\n",
    "    if target_users <= 0 or target_users >= len(users):\n",
    "        return set(users)\n",
    "    rnd = random.Random(seed)\n",
    "    return set(rnd.sample(users, target_users))\n",
    "\n",
    "def subset_behaviors(df: pd.DataFrame, keep_users: Set[str]) -> pd.DataFrame:\n",
    "    return df[df[\"user_id\"].astype(str).isin(keep_users)].copy()\n",
    "\n",
    "def filter_news_stream(news_path: str, keep_ids: Set[str], out_path: str):\n",
    "    \"\"\"\n",
    "    Stream filter news.tsv by first column (true news_id).\n",
    "    - Never writes a header\n",
    "    - Preserves each kept line verbatim (so JSON columns remain valid)\n",
    "    - Skips a header line automatically if the first token doesn't look like an 'N...' id.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    kept, total = 0, 0\n",
    "    with open(news_path, \"r\", encoding=\"utf-8\") as fin, open(out_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        first = True\n",
    "        for line in fin:\n",
    "            total += 1\n",
    "            # news_id is the substring before the first tab\n",
    "            tab = line.find(\"\\t\")\n",
    "            token = line if tab == -1 else line[:tab]\n",
    "            token = token.strip()\n",
    "\n",
    "            if first:\n",
    "                first = False\n",
    "                # If first line is a header (e.g., 'news_id' / 'news' / 'category' etc.), skip it\n",
    "                if not token.startswith(\"N\"):\n",
    "                    continue  # header-like -> drop\n",
    "            # keep only if the first field is an ID we need\n",
    "            if token in keep_ids:\n",
    "                fout.write(line)\n",
    "                kept += 1\n",
    "    print(f\"[news] {kept:,} rows kept out of ~{total:,} lines (train/news.tsv)\")\n",
    "\n",
    "def process_split(split_name: str, in_root: str, out_root: str, seed: int, target_users: int):\n",
    "    in_split = os.path.join(in_root, split_name)\n",
    "    out_split = os.path.join(out_root, split_name)\n",
    "    os.makedirs(out_split, exist_ok=True)\n",
    "\n",
    "    beh_in = os.path.join(in_split, \"behaviors.tsv\")\n",
    "    news_in = os.path.join(in_split, \"news.tsv\")\n",
    "    ent_in  = os.path.join(in_split, \"entity_embedding.vec\")\n",
    "    rel_in  = os.path.join(in_split, \"relation_embedding.vec\")\n",
    "\n",
    "    beh_out = os.path.join(out_split, \"behaviors.tsv\")\n",
    "    news_out = os.path.join(out_split, \"news.tsv\")\n",
    "    ent_out  = os.path.join(out_split, \"entity_embedding.vec\")\n",
    "    rel_out  = os.path.join(out_split, \"relation_embedding.vec\")\n",
    "\n",
    "    # Load & sample users\n",
    "    beh_df = read_behaviors(beh_in)\n",
    "    keep_users = sample_users(beh_df, target_users, seed)\n",
    "    beh_sub = subset_behaviors(beh_df, keep_users)\n",
    "    beh_sub.to_csv(beh_out, sep=\"\\t\", header=False, index=False)\n",
    "    print(f\"[{split_name}] behaviors written -> {beh_out} (rows: {len(beh_sub):,}, unique users: {beh_sub['user_id'].nunique():,})\")\n",
    "\n",
    "    # Get referenced news\n",
    "    keep_ids = extract_news_from_behaviors(beh_sub)\n",
    "    print(f\"[{split_name}] referenced news ids: {len(keep_ids):,}\")\n",
    "\n",
    "    # Filter news.tsv by first column only, NO HEADER written\n",
    "    print(f\"[{split_name}] filtering news.tsv -> {news_out}\")\n",
    "    filter_news_stream(news_in, keep_ids, news_out)\n",
    "\n",
    "    # Copy embeddings unchanged\n",
    "    if os.path.exists(ent_in): shutil.copyfile(ent_in, ent_out)\n",
    "    if os.path.exists(rel_in): shutil.copyfile(rel_in, rel_out)\n",
    "    print(f\"[{split_name}] Done.\\n\")\n",
    "\n",
    "# -------------------- run --------------------\n",
    "process_split(\"train/MINDsmall_train\", in_root, out_root, seed, train_users)\n",
    "\n",
    "if val_users == -1:\n",
    "    print(\"[val] Copying validation split unchanged...\")\n",
    "    in_val = os.path.join(in_root, \"val\")\n",
    "    out_val = os.path.join(out_root, \"val\")\n",
    "    os.makedirs(out_val, exist_ok=True)\n",
    "    for fname in [\"behaviors.tsv\", \"news.tsv\", \"entity_embedding.vec\", \"relation_embedding.vec\"]:\n",
    "        src = os.path.join(in_val, fname)\n",
    "        dst = os.path.join(out_val, fname)\n",
    "        if os.path.exists(src):\n",
    "            shutil.copyfile(src, dst)\n",
    "    print(\"[val] Done (unchanged).\")\n",
    "else:\n",
    "    process_split(\"val\", in_root, out_root, seed, val_users)\n",
    "\n",
    "print(\"All done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cca111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
