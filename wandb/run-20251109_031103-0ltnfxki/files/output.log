Using device: cpu
Training model NRMSbert
NRMSbert(
  (news_encoder): NewsEncoder(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 128, padding_idx=0)
        (position_embeddings): Embedding(512, 128)
        (token_type_embeddings): Embedding(2, 128)
        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-1): 2 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=128, out_features=512, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=512, out_features=128, bias=True)
              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=128, out_features=128, bias=True)
        (activation): Tanh()
      )
    )
    (pooler): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): Dropout(p=0.1, inplace=False)
      (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (3): SiLU()
    )
    (multihead_self_attention): MultiHeadSelfAttention(
      (W_Q): Linear(in_features=128, out_features=128, bias=True)
      (W_K): Linear(in_features=128, out_features=128, bias=True)
      (W_V): Linear(in_features=128, out_features=128, bias=True)
    )
    (additive_attention): AdditiveAttention(
      (linear): Linear(in_features=128, out_features=200, bias=True)
    )
  )
  (user_encoder): UserEncoder(
    (multihead_self_attention): MultiHeadSelfAttention(
      (W_Q): Linear(in_features=128, out_features=128, bias=True)
      (W_K): Linear(in_features=128, out_features=128, bias=True)
      (W_V): Linear(in_features=128, out_features=128, bias=True)
    )
    (additive_attention): AdditiveAttention(
      (linear): Linear(in_features=128, out_features=200, bias=True)
    )
  )
  (click_predictor): DotProductClickPredictor()
)
load original data:
00:00:01
Load training dataset with size 90200.
00:00:08
load val data:
00:00:08
Finish load val data:
00:00:14
Finish Build dataloader:
00:00:14
Start to do the model training:
00:00:14
