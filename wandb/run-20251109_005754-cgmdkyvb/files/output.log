Using device: cpu
Training model NRMSbert
NRMSbert(
  (news_encoder): NewsEncoder(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 128, padding_idx=0)
        (position_embeddings): Embedding(512, 128)
        (token_type_embeddings): Embedding(2, 128)
        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-1): 2 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=128, out_features=512, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=512, out_features=128, bias=True)
              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=128, out_features=128, bias=True)
        (activation): Tanh()
      )
    )
    (pooler): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): Dropout(p=0.1, inplace=False)
      (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (3): SiLU()
    )
    (multihead_self_attention): MultiHeadSelfAttention(
      (W_Q): Linear(in_features=128, out_features=128, bias=True)
      (W_K): Linear(in_features=128, out_features=128, bias=True)
      (W_V): Linear(in_features=128, out_features=128, bias=True)
    )
    (additive_attention): AdditiveAttention(
      (linear): Linear(in_features=128, out_features=200, bias=True)
    )
  )
  (user_encoder): UserEncoder(
    (multihead_self_attention): MultiHeadSelfAttention(
      (W_Q): Linear(in_features=128, out_features=128, bias=True)
      (W_K): Linear(in_features=128, out_features=128, bias=True)
      (W_V): Linear(in_features=128, out_features=128, bias=True)
    )
    (additive_attention): AdditiveAttention(
      (linear): Linear(in_features=128, out_features=200, bias=True)
    )
  )
  (click_predictor): DotProductClickPredictor()
)
load original data:
00:00:02
Load training dataset with size 0.
00:00:08
load val data:
00:00:08
Finish load val data:
00:00:12
Traceback (most recent call last):
  File "/gpfs/home2/scur1748/ir2-colbert-news/baseline/bert/train.py", line 356, in <module>
    train()
  File "/gpfs/home2/scur1748/ir2-colbert-news/baseline/bert/train.py", line 164, in train
    DataLoader(dataset,
  File "/home/scur1748/.conda/envs/newsrec/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 383, in __init__
    sampler = RandomSampler(dataset, generator=generator)  # type: ignore[arg-type]
  File "/home/scur1748/.conda/envs/newsrec/lib/python3.9/site-packages/torch/utils/data/sampler.py", line 165, in __init__
    raise ValueError(
ValueError: num_samples should be a positive integer value, but got num_samples=0
Traceback (most recent call last):
  File "/gpfs/home2/scur1748/ir2-colbert-news/baseline/bert/train.py", line 356, in <module>
    train()
  File "/gpfs/home2/scur1748/ir2-colbert-news/baseline/bert/train.py", line 164, in train
    DataLoader(dataset,
  File "/home/scur1748/.conda/envs/newsrec/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 383, in __init__
    sampler = RandomSampler(dataset, generator=generator)  # type: ignore[arg-type]
  File "/home/scur1748/.conda/envs/newsrec/lib/python3.9/site-packages/torch/utils/data/sampler.py", line 165, in __init__
    raise ValueError(
ValueError: num_samples should be a positive integer value, but got num_samples=0
